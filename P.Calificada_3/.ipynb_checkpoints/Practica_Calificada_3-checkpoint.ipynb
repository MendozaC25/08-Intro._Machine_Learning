{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3bf0a9-39da-4699-8e6e-19e7f3c5bc65",
   "metadata": {},
   "source": [
    "# **Lista de ejercicios 3 (30 de octubre, 2024)**\n",
    "## Introducción a Machine Learning para CCSS\n",
    "\n",
    "### Integrantes: \n",
    "\n",
    "- Victoria Olivera García (20171137)\n",
    "- Víctor Manuel Raico Arce (F1092609)\n",
    "- Fernando Mendoza Canal (20105246)\n",
    "- Paolo Gutierrez Chochoca (F1120328)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e66059-a4f4-4cd6-94fc-2e750f63f51a",
   "metadata": {},
   "source": [
    "#### **Instrucciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52420ee-0378-401b-b65d-12d6e2a4f8b0",
   "metadata": {},
   "source": [
    "**1. Temas abordados:** Esta lista de ejercicios se enfoca en los temas: Tree Based Models &\n",
    "Neural Networks.\n",
    "\n",
    "**2. Formación de grupos:** Se permite la formación de grupos de hasta 5 integrantes.\n",
    "\n",
    "**3. Puntuación de ejercicios:** La lista contiene 5 ejercicios. Cada ejercicio vale 4 puntos.\n",
    "\n",
    "**4. Formato de entrega:** La resolución de los ejercicios debe presentarse en un archivo jupyter-notebook con todas las celdas ejecutadas.\n",
    "\n",
    "**5. Fecha límite de entrega:** La fecha límite para la entrega es el miércoles 06 de noviembre a las 11:59 pm. Un representante del equipo debe subir su solucionario a la actividad correspondiente en la plataforma Canvas. Los nombres y códigos de todos los participantes deben ser incluidos en el solucionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef7725-0af0-49c3-b9f4-735f5909b66d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d4e6ff1-7aa2-44a5-a541-f001e31ca96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad743272-670b-41cc-9f1d-cc0371f719c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a306369-573f-4d9f-b238-daa8667d5a8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7c05f-5961-428f-ac50-a811349d9952",
   "metadata": {},
   "source": [
    "#### Brinde una explicación detallada del algoritmo que se utiliza para implementar un **Árbol de Regresión**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b190cd-d0e1-4793-a8a3-b15aab975e48",
   "metadata": {},
   "source": [
    "El Árbol de Regresión es un algoritmo de aprendizaje supervisado que se utiliza principalmente para problemas de regresión, es decir, aquellos en los que la variable objetivo es continua. Este algoritmo crea un modelo que divide los datos en grupos o \"regiones\" y luego ajusta una predicción constante para cada región, generalmente el valor medio de la variable objetivo en esa región.\n",
    "\n",
    "Pasos detallados para construir un **Árbol de Regresión**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4cf659-1650-41ef-aee3-7aca4b245795",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **1) Seleccionar el Mejor Punto de División (Split):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d7d69-c762-40ce-a986-eb71677ebdb0",
   "metadata": {},
   "source": [
    "- Para construir un Árbol de Regresión, se selecciona la variable y el punto de corte que mejor divide los datos en función de una métrica de error. El objetivo es dividir los datos de tal manera que cada subconjunto o rama del árbol tenga valores de la variable objetivo lo más homogéneos posible.\n",
    "\n",
    "- La métrica comúnmente utilizada para medir la calidad de una división es el **Error Cuadrático Medio** $(MSE)$. El $MSE$ mide el promedio del cuadrado de las diferencias entre los valores observados y el valor promedio de la variable objetivo en esa región:\n",
    "        $$MSE=\\frac{1}{n}\\sum^{n}_{i=1}(y_{i}−\\overline{y})^{2}$$\n",
    "        \n",
    "- El algoritmo evalúa todas las posibles divisiones y elige la que minimiza el error en las regiones resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ec602-d0ff-4699-b85e-ad248e4068db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **2) Dividir los Datos:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a474ea2-0a12-46c5-95b2-25b8f800d1ff",
   "metadata": {},
   "source": [
    "- Una vez seleccionado el mejor punto de corte, el conjunto de datos se divide en dos subconjuntos según ese criterio.\n",
    "\n",
    "- El proceso de división se repite recursivamente para cada subconjunto, creando nuevas divisiones y ramas en el árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978f739-8d82-4f7e-a911-1cb6cfc1d794",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **3) Parar la Creación de Nuevas Divisiones:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bea099-bb70-498c-873d-b4c7c1b24618",
   "metadata": {},
   "source": [
    "- El proceso de división continúa hasta que se alcanza un criterio de parada. Este criterio puede ser uno o varios de los siguientes:\n",
    "\n",
    "    Profundidad máxima del árbol: El número máximo de niveles del árbol está limitado.\n",
    "\n",
    "    Número mínimo de datos en una hoja: Si el número de muestras en un nodo es menor que un umbral, no se crean divisiones adicionales.\n",
    "\n",
    "    Mínima reducción en el error: Si la reducción en el error al hacer una nueva división es menor que un cierto umbral, el proceso de división se detiene.\n",
    "\n",
    "- Al finalizar el crecimiento del árbol, cada nodo terminal representa una región de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b3f6b-7b8e-4a7b-8c46-e2dc3f9e5571",
   "metadata": {},
   "source": [
    "##### **4) Predicción:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de8f61-fc10-4e48-a970-ad129cd84cb4",
   "metadata": {},
   "source": [
    "- Una vez entrenado el Árbol de Regresión, se puede utilizar para hacer predicciones.\n",
    "\n",
    "- Para predecir el valor de la variable objetivo para un nuevo dato, se comienza en la raíz del árbol y se recorre el árbol siguiendo las condiciones de cada nodo hasta llegar a una hoja.\n",
    "\n",
    "- El valor predicho para el nuevo dato será el valor promedio de la variable objetivo de los datos en la hoja alcanzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a993fc-9621-4ec3-b53f-2b71ad5839d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Ventajas y Desventajas del Árbol de Regresión**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50357904-d7ac-46e3-9b57-15b216a41b42",
   "metadata": {},
   "source": [
    "- **Ventajas**\n",
    "\n",
    "    Fácil de interpretar y visualizar.\n",
    "    No requiere una normalización de los datos.\n",
    "    Puede capturar relaciones no lineales entre las variables.\n",
    "\n",
    "- **Desventajas**\n",
    "\n",
    "    Son propensos al sobreajuste, especialmente si no se limita la profundidad del árbol.\n",
    "    La predicción es constante dentro de cada región (no puede capturar cambios suaves en la variable objetivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70e14d-7a7e-44f3-bd7a-079081b3302e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Optimización: Árboles Podados y Ensamblados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd793c-1f15-45ba-9cbd-e1fadecce126",
   "metadata": {},
   "source": [
    "Para mejorar el rendimiento de un Árbol de Regresión, es común usar métodos de poda o algoritmos de ensamble como Random Forests y Gradient Boosting. Estos métodos reducen el sobreajuste y aumentan la precisión al combinar múltiples árboles o podando los nodos menos importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e4762-bbab-4dff-8ee1-3fbce099a9cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0dbae-81c5-4412-a18d-cc012c8d3cd8",
   "metadata": {},
   "source": [
    "#### Considere la dataset Carseats para predecir Sales como variable cuantitativa (puede encontrar el conjunto de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/carseats.csv)). Para ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "deb4dab3-e80e-4bc6-9899-d48d6effa26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>ShelveLoc_Good</th>\n",
       "      <th>ShelveLoc_Medium</th>\n",
       "      <th>Urban_No</th>\n",
       "      <th>Urban_Yes</th>\n",
       "      <th>US_No</th>\n",
       "      <th>US_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price  Age  Education  \\\n",
       "0   9.50        138      73           11         276    120   42         17   \n",
       "1  11.22        111      48           16         260     83   65         10   \n",
       "2  10.06        113      35           10         269     80   59         12   \n",
       "3   7.40        117     100            4         466     97   55         14   \n",
       "4   4.15        141      64            3         340    128   38         13   \n",
       "\n",
       "   ShelveLoc_Good  ShelveLoc_Medium  Urban_No  Urban_Yes  US_No  US_Yes  \n",
       "0               0                 0         0          1      0       1  \n",
       "1               1                 0         0          1      0       1  \n",
       "2               0                 1         0          1      0       1  \n",
       "3               0                 1         0          1      0       1  \n",
       "4               0                 0         0          1      1       0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se carga la base de datos directamente\n",
    "carseats = pd.read_csv('https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/carseats.csv')\n",
    "\n",
    "carseats = carseats.dropna()\n",
    "carseats = carseats.drop(columns = ['Unnamed: 0'])\n",
    "carseats = pd.get_dummies(carseats, dtype='int')\n",
    "carseats = carseats.drop(columns = ['ShelveLoc_Bad'])\n",
    "carseats = carseats.reindex()\n",
    "carseats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a42ae-328f-44cc-a961-81c6e4f17021",
   "metadata": {},
   "source": [
    "#### **a)** Divida los datos en conjuntos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d7e9a60-995c-4fcc-a2bd-ebf9ef279271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento: (320, 13), (320,)\n",
      "Conjunto de prueba: (80, 13), (80,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en variables independientes (X) y dependiente (y)\n",
    "X = carseats.drop(columns=['Sales'])\n",
    "y = carseats['Sales']\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Mostrar las dimensiones de los conjuntos\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47693c6-69bf-493d-972c-fc9729b5386b",
   "metadata": {},
   "source": [
    "#### **b)** Ajuste un árbol de regresión al conjunto de entrenamiento. Interprete los resultados. <br>¿Qué valor de $MSE$ se obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61f3ba20-7a52-478a-a5d5-cf4e5efcf1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE en el conjunto de prueba es: 5.88\n"
     ]
    }
   ],
   "source": [
    "# Crear y ajustar el modelo de árbol de regresión\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular el MSE en el conjunto de prueba\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"El MSE en el conjunto de prueba es: {mse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e33a2-aeea-404c-9266-5bd77db9aff0",
   "metadata": {},
   "source": [
    "#### **c)** Utilice el método **Bagging** para analizar estos datos. <br>¿Qué valor de $MSE$ obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0861a6ae-82ea-4533-bb2b-b6a2baf48580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE con Bagging en el conjunto de prueba es: 3.16\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo de Bagging\n",
    "bagging_model = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(), \n",
    "    n_estimators=100, #Utiliza 100 árboles en el modelo de Bagging\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "# Calcular el MSE en el conjunto de prueba\n",
    "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"El MSE con Bagging en el conjunto de prueba es: {mse_bagging:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0c5cb-2979-4e08-b7fd-10ce15e25131",
   "metadata": {},
   "source": [
    "#### **d)** Utilice el método **Random Forest** para analizar los datos. Repita el procedimiento descrito en el punto 3. <br>Describa el efecto de $m$, el número de variables consideradas en cada división, sobre la tasa de error obtenida. <br>Utilice la función $features\\_importance()$ para determinar qué variables son las más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f45ff48d-fdbf-4448-b31d-341ac933e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE con Random Forest en el conjunto de prueba es: 4.05\n"
     ]
    }
   ],
   "source": [
    "##### Ajuste del modelo y cálculo de MSE\n",
    "\n",
    "# Crear y ajustar el modelo de Random Forest con max_features='sqrt'\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_features='sqrt',  # Uso de la raíz cuadrada del número de características\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular el MSE en el conjunto de prueba\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"El MSE con Random Forest en el conjunto de prueba es: {mse_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5f62e3fd-b516-4569-a75c-d2ba991a4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features=sqrt: MSE=4.05\n",
      "max_features=log2: MSE=4.05\n",
      "max_features=None: MSE=3.15\n"
     ]
    }
   ],
   "source": [
    "##### Efecto del número de características (max_features)\n",
    "mse_values = []\n",
    "features_range = ['sqrt', 'log2', None]  # Diferentes valores para max_features\n",
    "\n",
    "for m in features_range:\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, max_features=m, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_values.append(mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "# Mostrar los resultados\n",
    "for i, m in enumerate(features_range):\n",
    "    print(f\"max_features={m}: MSE={mse_values[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2f53791-fcda-4ed3-93df-1bbd04545c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Price, Importancia: 0.3079\n",
      "Variable: ShelveLoc_Good, Importancia: 0.1984\n",
      "Variable: Age, Importancia: 0.1194\n",
      "Variable: CompPrice, Importancia: 0.0934\n",
      "Variable: Advertising, Importancia: 0.0821\n"
     ]
    }
   ],
   "source": [
    "##### Importancia de las características\n",
    "\n",
    "# Obtener y visualizar las importancias de las características\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "for i in np.argsort(importances)[::-1][:5]:  # Top 5 variables\n",
    "    print(f\"Variable: {X_train.columns[i]}, Importancia: {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9bbe3-dddc-482a-a09d-c5a2496d581f",
   "metadata": {},
   "source": [
    "**Resultados e Interpretación**\n",
    "\n",
    "- MSE:\n",
    "El valor del MSE variará según el valor de max_features. Idealmente, deberías buscar el menor MSE en este análisis para determinar la configuración óptima.\n",
    "\n",
    "- Importancia de las características:\n",
    "Este análisis identificará las variables más influyentes en las predicciones, permitiéndote enfocar la interpretación en ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d4d4a-34dd-4595-9315-ae3a81bcfd77",
   "metadata": {},
   "source": [
    "#### **e)** Utilice el método **Gradient Boosting**. Repita el procedimiento descrito en el punto 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f459fe9d-d772-4ea8-a545-090c0c22d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE con Gradient Boosting en el conjunto de prueba es: 2.03\n"
     ]
    }
   ],
   "source": [
    "##### Código para Gradient Boosting\n",
    "\n",
    "# Crear y ajustar el modelo de Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=100,  # Número de árboles\n",
    "    learning_rate=0.1,  # Tasa de aprendizaje\n",
    "    max_depth=3,  # Profundidad máxima de cada árbol\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Calcular el MSE en el conjunto de prueba\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"El MSE con Gradient Boosting en el conjunto de prueba es: {mse_gb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "966ec8f9-a9a6-4ef1-b442-93e68e13f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Price, Importancia: 0.3337\n",
      "Variable: ShelveLoc_Good, Importancia: 0.2064\n",
      "Variable: CompPrice, Importancia: 0.1156\n",
      "Variable: Age, Importancia: 0.1122\n",
      "Variable: Advertising, Importancia: 0.0906\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Importancia de las características\n",
    "\n",
    "# Obtener y visualizar las importancias de las características\n",
    "importances = gb_model.feature_importances_\n",
    "\n",
    "# Mostrar las variables más importantes\n",
    "for i in np.argsort(importances)[::-1][:5]:  # Top 5 variables\n",
    "    print(f\"Variable: {X_train.columns[i]}, Importancia: {importances[i]:.4f}\")\n",
    "\n",
    "# Visualización de las importancias\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X_train.columns[np.argsort(importances)], importances[np.argsort(importances)])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Importancia de las características - Gradient Boosting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcacd7-89f9-42b6-8612-003a2de1a9d3",
   "metadata": {},
   "source": [
    "**Interpretación**\n",
    "\n",
    "- MSE:\n",
    "\n",
    "Compara el valor del MSE con los resultados obtenidos de Random Forest y Bagging. Generalmente, Gradient Boosting ofrece un mejor rendimiento en problemas donde pequeñas mejoras incrementales ayudan a reducir el error.\n",
    "\n",
    "- Importancia de las características:\n",
    "\n",
    "Analiza qué variables son las más relevantes para el modelo. Esto te ayudará a identificar factores clave en las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e41005-f56b-455f-9913-a2d0bfdc9be9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 3**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4397-5569-48be-9b76-f978e69d7463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aplique los métodos **Boosting, Bagging y Random Forest** a una dataset de su elección. Asegúrese de dividir los datos en los conjuntos de entrenamiento y de prueba, ajustar los modelos sobre el conjunto de entrenamiento y evaluar su desempeño sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e620f846-263f-445b-a7cd-531b0b8c88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usará el dataset College\n",
    "college = pd.read_csv('https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/college.csv')\n",
    "college = college.iloc[:, 1:]\n",
    "\n",
    "# Codificando a valores binarios la variable 'Private'\n",
    "mapa = {\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "}\n",
    "\n",
    "college['Private'] = college['Private'].map(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "198a00b2-a5a2-4151-86a4-935bd21b10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo variables explicativas y variable explicada\n",
    "X = college.drop(columns='Apps')\n",
    "y = college['Apps']\n",
    "\n",
    "# Dividiendo los datos entre train y test (30% para el data test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20241104)\n",
    "\n",
    "# Escalando los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ac422-1c67-497d-8a8b-5b64d7fe1c46",
   "metadata": {},
   "source": [
    "#### ¿Cuán precisos son los resultados si los compara con métodos regresión lineal/logística y/o métodos de **Regularización**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1aed294f-9b83-4b71-8b1f-1dc8ba888a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos Lasso y Ridge se ajusta primero los alpha óptimos:\n",
    "# Definir el rango de alphas para Lasso y Ridge\n",
    "alpha_values = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Modelo Lasso con GridSearchCV\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid=alpha_values, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "best_lasso = lasso_cv.best_estimator_\n",
    "\n",
    "# Modelo Ridge con GridSearchCV\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid=alpha_values, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "best_ridge = ridge_cv.best_estimator_\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': best_lasso,\n",
    "    'Ridge': best_ridge,\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Bagging': BaggingRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Boosting': GradientBoostingRegressor(n_estimators=100, random_state=20241104)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "250174e0-1bce-4558-a653-e0cb32f417d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.479619e+06</td>\n",
       "      <td>1216.395955</td>\n",
       "      <td>0.863759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.415299e+06</td>\n",
       "      <td>1189.663551</td>\n",
       "      <td>0.869682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.477369e+06</td>\n",
       "      <td>1215.470580</td>\n",
       "      <td>0.863966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>8.833714e+05</td>\n",
       "      <td>939.878407</td>\n",
       "      <td>0.918661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>8.615275e+05</td>\n",
       "      <td>928.185066</td>\n",
       "      <td>0.920672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosting</th>\n",
       "      <td>8.827712e+05</td>\n",
       "      <td>939.559055</td>\n",
       "      <td>0.918716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE         RMSE        R2\n",
       "Linear Regression  1.479619e+06  1216.395955  0.863759\n",
       "Lasso              1.415299e+06  1189.663551  0.869682\n",
       "Ridge              1.477369e+06  1215.470580  0.863966\n",
       "Random Forest      8.833714e+05   939.878407  0.918661\n",
       "Bagging            8.615275e+05   928.185066  0.920672\n",
       "Boosting           8.827712e+05   939.559055  0.918716"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3948130-0caa-4ba5-8fb2-77f630384cbd",
   "metadata": {},
   "source": [
    "#### ¿Cuál de todos los modelos implementados muestra un mejor desempeño?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2871c-5a8b-47d6-a48d-3624f578938f",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "\n",
    "Según lo observado en el cuadro anterior, se tiene los siguientes resultados:\n",
    "- El modelo *Bagging* muestra el menor RMSE (928.19), junto con el mayor $R^2$, lo que sugiere que es el modelo con mejor desempeño en esta comparación de modelos.\n",
    "- Los modelos de *Random Forest* y *Boosting* están cerca del modelo *Bagging*.\n",
    "- Los modelos de *regresión lineal* y de regularización (*Ridge* y *Lasso*) tienen un peor rendimiento en el RMSE y $R^2$.\n",
    "- En conclusión, el modelo *Bagging* muestra el mejor desempeño dado que tiene el menor RMSE y mayor $R^2$ en comparación con los resultados de los otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e6e9e-ce7d-46ef-bee2-94222d03496a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e57994-d1e3-4b83-80b4-4b717b927336",
   "metadata": {},
   "source": [
    "#### Implemente una red neuronal con la database **Default** (puede encontrar el set de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/default.csv)). Use una capa oculta con 10 unidades y regularización por droput. Compare el desempeño de clasificación con respecto al de la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3c2d2992-63c4-4405-bab3-c23ae141ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 default student      balance        income\n",
      "0           0      No      No   729.526495  44361.625074\n",
      "1           1      No     Yes   817.180407  12106.134700\n",
      "2           2      No      No  1073.549164  31767.138947\n",
      "3           3      No      No   529.250605  35704.493935\n",
      "4           4      No      No   785.655883  38463.495879\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos Default\n",
    "default = pd.read_csv(\"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/default.csv\")\n",
    "\n",
    "# Verificamos los primeros datos\n",
    "print(default.head())\n",
    "\n",
    "# Separaramos las características (X) y el objetivo (y)\n",
    "X = default[['balance', 'income']]  # Ajustar según las columnas relevantes\n",
    "y = default['default'].apply(lambda x: 1 if x == 'Yes' else 0)  # Convertir a binario\n",
    "\n",
    "# Dividimos en conjuntos de entrenamiento y prueba (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizamos las características para la red neuronal\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0009efa0-d326-4754-b289-bb3a600241b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la regresión logística: 0.9695\n"
     ]
    }
   ],
   "source": [
    "#PASO2: ENTRENAMOS EL MODELO\n",
    "\n",
    "# Definir y entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Precisión de la regresión logística: {accuracy_logistic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eeed7b58-74f2-4439-ac37-8808562197b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5993 - accuracy: 0.7067 - val_loss: 0.4063 - val_accuracy: 0.9606\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.9262 - val_loss: 0.2562 - val_accuracy: 0.9638\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9608 - val_loss: 0.1804 - val_accuracy: 0.9638\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9680 - val_loss: 0.1353 - val_accuracy: 0.9638\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9681 - val_loss: 0.1150 - val_accuracy: 0.9638\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9681 - val_loss: 0.1044 - val_accuracy: 0.9638\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9684 - val_loss: 0.0977 - val_accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9681 - val_loss: 0.0925 - val_accuracy: 0.9638\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9683 - val_loss: 0.0884 - val_accuracy: 0.9638\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9681 - val_loss: 0.0847 - val_accuracy: 0.9638\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9681 - val_loss: 0.0820 - val_accuracy: 0.9638\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9688 - val_loss: 0.0807 - val_accuracy: 0.9638\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9689 - val_loss: 0.0794 - val_accuracy: 0.9638\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9683 - val_loss: 0.0788 - val_accuracy: 0.9638\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9686 - val_loss: 0.0779 - val_accuracy: 0.9638\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9683 - val_loss: 0.0777 - val_accuracy: 0.9638\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9698 - val_loss: 0.0770 - val_accuracy: 0.9638\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9702 - val_loss: 0.0769 - val_accuracy: 0.9638\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9711 - val_loss: 0.0773 - val_accuracy: 0.9638\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9695 - val_loss: 0.0778 - val_accuracy: 0.9638\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9695 - val_loss: 0.0775 - val_accuracy: 0.9638\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9691 - val_loss: 0.0776 - val_accuracy: 0.9638\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9689 - val_loss: 0.0777 - val_accuracy: 0.9638\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9700 - val_loss: 0.0779 - val_accuracy: 0.9638\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9691 - val_loss: 0.0782 - val_accuracy: 0.9638\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9703 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9695 - val_loss: 0.0777 - val_accuracy: 0.9638\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9703 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9702 - val_loss: 0.0785 - val_accuracy: 0.9638\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9694 - val_loss: 0.0784 - val_accuracy: 0.9638\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.9717 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9698 - val_loss: 0.0783 - val_accuracy: 0.9638\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 0.0786 - val_accuracy: 0.9638\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9702 - val_loss: 0.0782 - val_accuracy: 0.9638\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9698 - val_loss: 0.0785 - val_accuracy: 0.9638\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9705 - val_loss: 0.0792 - val_accuracy: 0.9638\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9703 - val_loss: 0.0789 - val_accuracy: 0.9638\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9708 - val_loss: 0.0789 - val_accuracy: 0.9638\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9695 - val_loss: 0.0790 - val_accuracy: 0.9638\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9703 - val_loss: 0.0787 - val_accuracy: 0.9638\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9703 - val_loss: 0.0784 - val_accuracy: 0.9638\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9700 - val_loss: 0.0784 - val_accuracy: 0.9638\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9706 - val_loss: 0.0787 - val_accuracy: 0.9638\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9709 - val_loss: 0.0787 - val_accuracy: 0.9638\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9698 - val_loss: 0.0784 - val_accuracy: 0.9638\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9703 - val_loss: 0.0791 - val_accuracy: 0.9638\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9703 - val_loss: 0.0790 - val_accuracy: 0.9638\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9714 - val_loss: 0.0783 - val_accuracy: 0.9638\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9717 - val_loss: 0.0783 - val_accuracy: 0.9644\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9703 - val_loss: 0.0778 - val_accuracy: 0.9644\n"
     ]
    }
   ],
   "source": [
    "#Implementamos y entrenamos la red neuronal con keras\n",
    "\n",
    "# Definir la red neuronal\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),  # Capa oculta con 10 unidades\n",
    "    Dropout(0.5),  # Dropout con una tasa del 50%\n",
    "    Dense(1, activation='sigmoid')  # Capa de salida para clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4e0494fe-ae07-424d-a7b9-437bef281ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "Precisión de la red neuronal: 0.9655\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el desempeño  de la red neuronal en el conjunto de prueba\n",
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Precisión de la red neuronal: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a88d8f8f-8681-4c39-bef5-8d5931184bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación del desempeño de clasificación:\n",
      " - Precisión de la regresión logística: 0.9695\n",
      " - Precisión de la red neuronal: 0.9655\n"
     ]
    }
   ],
   "source": [
    "#Comparamos resultados\n",
    "print(\"Comparación del desempeño de clasificación:\")\n",
    "print(f\" - Precisión de la regresión logística: {accuracy_logistic:.4f}\")\n",
    "print(f\" - Precisión de la red neuronal: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68daab-14ba-4dbd-a007-635ccbe462d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d75a3-8a05-43a9-8246-ee34881c4c40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Considere la implementación del modelo de **Redes Neuronales Convolucionales** $(CNN)$ utilizando la dataset **CIFAR 100** presentada en el notebook de clases. En esta implementación inicial, se alcanzó un **Accuracy** aproximado de **0.44**. Su tarea es desarrollar una nueva implementación que supere este valor de **Accuracy**. Para lograrlo, se le anima a experimentar con los siguientes aspectos del modelo:\n",
    "\n",
    "- **Arquitectura del Modelo:** Puede considerar la adición de más capas convolucionales y de pooling, incrementar el número de filtros por capa, o modificar el tamaño del kernel.\n",
    "\n",
    "- **Regularización:** Experimente con diferentes tasas de dropout para prevenir el sobreajuste.\n",
    "\n",
    "- **Entrenamiento:** Pruebe con distintos tamaños de batch que puedan influir en la convergencia del modelo durante el entrenamiento.\n",
    "\n",
    "- **Optimización:** Evalúe el uso de diferentes algoritmos de optimización para verificar si mejoran la precisión del modelo.\n",
    "\n",
    "#### La meta es ajustar estos parámetros para superar el **Accuracy** de **0.44** previamente alcanzado. Documente todas las modificaciones realizadas y los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ff7e8-20ba-4f63-900f-66fcb8a63bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
