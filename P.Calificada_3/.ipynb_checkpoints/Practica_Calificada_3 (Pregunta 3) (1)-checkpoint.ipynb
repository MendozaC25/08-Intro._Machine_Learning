{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3bf0a9-39da-4699-8e6e-19e7f3c5bc65",
   "metadata": {},
   "source": [
    "# **Lista de ejercicios 3 (30 de octubre, 2024)**\n",
    "## Introducción a Machine Learning para CCSS\n",
    "\n",
    "### Integrantes: \n",
    "\n",
    "- Victoria Olivera García (20171137)\n",
    "- Víctor Manuel Raico Arce (F1092609)\n",
    "- Fernando Mendoza Canal (20105246)\n",
    "- Paolo Gutierrez Chochoca (F1120328)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e66059-a4f4-4cd6-94fc-2e750f63f51a",
   "metadata": {},
   "source": [
    "#### **Instrucciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52420ee-0378-401b-b65d-12d6e2a4f8b0",
   "metadata": {},
   "source": [
    "**1. Temas abordados:** Esta lista de ejercicios se enfoca en los temas: Tree Based Models &\n",
    "Neural Networks.\n",
    "\n",
    "**2. Formación de grupos:** Se permite la formación de grupos de hasta 5 integrantes.\n",
    "\n",
    "**3. Puntuación de ejercicios:** La lista contiene 5 ejercicios. Cada ejercicio vale 4 puntos.\n",
    "\n",
    "**4. Formato de entrega:** La resolución de los ejercicios debe presentarse en un archivo jupyter-notebook con todas las celdas ejecutadas.\n",
    "\n",
    "**5. Fecha límite de entrega:** La fecha límite para la entrega es el miércoles 06 de noviembre a las 11:59 pm. Un representante del equipo debe subir su solucionario a la actividad correspondiente en la plataforma Canvas. Los nombres y códigos de todos los participantes deben ser incluidos en el solucionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef7725-0af0-49c3-b9f4-735f5909b66d",
   "metadata": {},
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4e6ff1-7aa2-44a5-a541-f001e31ca96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlxtend in c:\\users\\equipo\\appdata\\roaming\\python\\python311\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\equipo\\appdata\\roaming\\python\\python311\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\equipo\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad743272-670b-41cc-9f1d-cc0371f719c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a306369-573f-4d9f-b238-daa8667d5a8f",
   "metadata": {},
   "source": [
    "### **Pregunta 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7c05f-5961-428f-ac50-a811349d9952",
   "metadata": {},
   "source": [
    "#### Brinde una explicación detallada del algoritmo que se utiliza para implementar un **Árbol de Regresión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed2725-d8a3-4899-8882-acff9ceb1fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57e4762-bbab-4dff-8ee1-3fbce099a9cb",
   "metadata": {},
   "source": [
    "### **Pregunta 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0dbae-81c5-4412-a18d-cc012c8d3cd8",
   "metadata": {},
   "source": [
    "#### Considere la dataset Carseats para predecir Sales como variable cuantitativa (puede encontrar el conjunto de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/carseats.csv)). Para ello:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a42ae-328f-44cc-a961-81c6e4f17021",
   "metadata": {},
   "source": [
    "#### **a)** Divida los datos en conjuntos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e9a60-995c-4fcc-a2bd-ebf9ef279271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47693c6-69bf-493d-972c-fc9729b5386b",
   "metadata": {},
   "source": [
    "#### **b)** Ajuste un árbol de regresión al conjunto de entrenamiento. Interprete los resultados. <br>¿Qué valor de $MSE$ se obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3ba20-7a52-478a-a5d5-cf4e5efcf1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee2e33a2-aeea-404c-9266-5bd77db9aff0",
   "metadata": {},
   "source": [
    "#### **c)** Utilice el método **Bagging** para analizar estos datos. <br>¿Qué valor de $MSE$ obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861a6ae-82ea-4533-bb2b-b6a2baf48580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cde0c5cb-2979-4e08-b7fd-10ce15e25131",
   "metadata": {},
   "source": [
    "#### **d)** Utilice el método **Random Forest** para analizar los datos. Repita el procedimiento descrito en el punto 3. <br>Describa el efecto de $m$, el número de variables consideradas en cada división, sobre la tasa de error obtenida. <br>Utilice la función $features\\_importance()$ para determinar qué variables son las más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ff48d-fdbf-4448-b31d-341ac933e4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139d4d4a-34dd-4595-9315-ae3a81bcfd77",
   "metadata": {},
   "source": [
    "#### **e)** Utilice el método **Gradient Boosting**. Repita el procedimiento descrito en el punto 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459fe9d-d772-4ea8-a545-090c0c22d465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e41005-f56b-455f-9913-a2d0bfdc9be9",
   "metadata": {},
   "source": [
    "### **Pregunta 3**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4397-5569-48be-9b76-f978e69d7463",
   "metadata": {},
   "source": [
    "#### Aplique los métodos **Boosting, Bagging y Random Forest** a una dataset de su elección. Asegúrese de dividir los datos en los conjuntos de entrenamiento y de prueba, ajustar los modelos sobre el conjunto de entrenamiento y evaluar su desempeño sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usará el dataset College\n",
    "ruta = \"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/college.csv\"\n",
    "data = pd.read_csv(ruta)\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Codificando a valores binarios la variable 'Private'\n",
    "mapa = {\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "}\n",
    "\n",
    "data['Private'] = data['Private'].map(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58439e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo variables explicativas y variable explicada\n",
    "X = data.drop(columns='Apps')\n",
    "y = data['Apps']\n",
    "\n",
    "# Dividiendo los datos entre train y test (30% para el data test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20241104)\n",
    "\n",
    "# Escalando los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81df7b7",
   "metadata": {},
   "source": [
    "#### ¿Cuán precisos son los resultados si los compara con métodos regresión lineal/logística y/o métodos de **Regularización**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47528a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos Lasso y Ridge se ajusta primero los alpha óptimos:\n",
    "# Definir el rango de alphas para Lasso y Ridge\n",
    "alpha_values = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Modelo Lasso con GridSearchCV\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid=alpha_values, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "best_lasso = lasso_cv.best_estimator_\n",
    "\n",
    "# Modelo Ridge con GridSearchCV\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid=alpha_values, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "best_ridge = ridge_cv.best_estimator_\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': best_lasso,\n",
    "    'Ridge': best_ridge,\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Bagging': BaggingRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Boosting': GradientBoostingRegressor(n_estimators=100, random_state=20241104)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fa45a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.479619e+06</td>\n",
       "      <td>1216.395955</td>\n",
       "      <td>0.863759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.415299e+06</td>\n",
       "      <td>1189.663551</td>\n",
       "      <td>0.869682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.477369e+06</td>\n",
       "      <td>1215.470580</td>\n",
       "      <td>0.863966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>8.833714e+05</td>\n",
       "      <td>939.878407</td>\n",
       "      <td>0.918661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>8.615275e+05</td>\n",
       "      <td>928.185066</td>\n",
       "      <td>0.920672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosting</th>\n",
       "      <td>8.827712e+05</td>\n",
       "      <td>939.559055</td>\n",
       "      <td>0.918716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE         RMSE        R2\n",
       "Linear Regression  1.479619e+06  1216.395955  0.863759\n",
       "Lasso              1.415299e+06  1189.663551  0.869682\n",
       "Ridge              1.477369e+06  1215.470580  0.863966\n",
       "Random Forest      8.833714e+05   939.878407  0.918661\n",
       "Bagging            8.615275e+05   928.185066  0.920672\n",
       "Boosting           8.827712e+05   939.559055  0.918716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511423ab",
   "metadata": {},
   "source": [
    "#### ¿Cuál de todos los modelos implementados muestra un mejor desempeño?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940774da",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "\n",
    "Según lo observado en el cuadro anterior, se tiene los siguientes resultados:\n",
    "- El modelo *Bagging* muestra el menor RMSE (928.19), junto con el mayor $R^2$, lo que sugiere que es el modelo con mejor desempeño en esta comparación de modelos.\n",
    "- Los modelos de *Random Forest* y *Boosting* están cerca del modelo *Bagging*.\n",
    "- Los modelos de *regresión lineal* y de regularización (*Ridge* y *Lasso*) tienen un peor rendimiento en el RMSE y $R^2$.\n",
    "- En conclusión, el modelo *Bagging* muestra el mejor desempeño dado que tiene el menor RMSE y mayor $R^2$ en comparación con los resultados de los otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e6e9e-ce7d-46ef-bee2-94222d03496a",
   "metadata": {},
   "source": [
    "### **Pregunta 4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e57994-d1e3-4b83-80b4-4b717b927336",
   "metadata": {},
   "source": [
    "#### Implemente una red neuronal con la database **Default** (puede encontrar el set de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/default.csv)). Use una capa oculta con 10 unidades y regularización por droput. Compare el desempeño de clasificación con respecto al de la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b737a43-4835-4e56-a648-9f61e47c1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/390.2 MB 10.6 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 2.0/390.2 MB 25.5 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 3.7/390.2 MB 29.8 MB/s eta 0:00:13\n",
      "    --------------------------------------- 5.4/390.2 MB 31.1 MB/s eta 0:00:13\n",
      "    --------------------------------------- 7.1/390.2 MB 32.3 MB/s eta 0:00:12\n",
      "    --------------------------------------- 9.1/390.2 MB 34.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 11.4/390.2 MB 40.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 13.2/390.2 MB 40.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 15.1/390.2 MB 43.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 17.2/390.2 MB 43.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 20.0/390.2 MB 46.9 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 22.4/390.2 MB 46.7 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 26.2/390.2 MB 65.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 28.7/390.2 MB 65.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 31.1/390.2 MB 65.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 33.7/390.2 MB 59.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 36.1/390.2 MB 54.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 38.4/390.2 MB 54.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 40.8/390.2 MB 50.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 44.0/390.2 MB 54.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 48.0/390.2 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 50.9/390.2 MB 72.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 54.3/390.2 MB 72.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 56.8/390.2 MB 65.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 59.7/390.2 MB 59.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 61.4/390.2 MB 54.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 63.4/390.2 MB 50.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 64.8/390.2 MB 46.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 66.7/390.2 MB 43.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 69.2/390.2 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 72.0/390.2 MB 46.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 76.0/390.2 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 78.2/390.2 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 81.1/390.2 MB 65.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 83.5/390.2 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 85.8/390.2 MB 54.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 89.0/390.2 MB 59.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 91.2/390.2 MB 54.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 93.7/390.2 MB 54.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 96.6/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 99.4/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 101.6/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 103.9/390.2 MB 54.4 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 106.6/390.2 MB 54.4 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 109.2/390.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 111.6/390.2 MB 54.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 114.2/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 115.3/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 115.3/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   ----------- --------------------------- 115.3/390.2 MB 38.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 115.3/390.2 MB 38.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 115.3/390.2 MB 38.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 116.1/390.2 MB 23.4 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 118.8/390.2 MB 24.2 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 121.3/390.2 MB 23.4 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 123.6/390.2 MB 23.4 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 125.9/390.2 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 128.3/390.2 MB 54.4 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 131.2/390.2 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 133.7/390.2 MB 54.4 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 136.8/390.2 MB 59.8 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 140.1/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 142.6/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 146.1/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 149.2/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 151.1/390.2 MB 59.5 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 153.9/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 157.3/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 160.2/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 163.3/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 166.2/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 168.6/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 170.6/390.2 MB 54.4 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 173.4/390.2 MB 54.4 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 176.7/390.2 MB 54.4 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 179.6/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 182.6/390.2 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 184.9/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 187.7/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 190.5/390.2 MB 59.8 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 192.9/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 195.9/390.2 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 198.2/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 200.7/390.2 MB 54.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 203.5/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 205.8/390.2 MB 54.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 208.5/390.2 MB 59.5 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 211.5/390.2 MB 59.8 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 214.4/390.2 MB 65.6 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 217.1/390.2 MB 65.6 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 219.7/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 222.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 224.1/390.2 MB 21.8 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 227.5/390.2 MB 22.6 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 229.9/390.2 MB 21.8 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 232.6/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 235.7/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 238.8/390.2 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 241.2/390.2 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 244.0/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 247.2/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.5/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.5/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.5/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.5/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.5/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 249.9/390.2 MB 25.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 252.3/390.2 MB 25.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 253.8/390.2 MB 25.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 255.5/390.2 MB 22.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 258.2/390.2 MB 22.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 260.7/390.2 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 264.3/390.2 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 266.5/390.2 MB 59.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 268.3/390.2 MB 54.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 269.6/390.2 MB 50.4 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 271.6/390.2 MB 46.7 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 273.3/390.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 275.0/390.2 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 276.2/390.2 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 278.1/390.2 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 280.1/390.2 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 281.7/390.2 MB 36.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 283.2/390.2 MB 36.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 284.8/390.2 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 286.2/390.2 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 287.6/390.2 MB 34.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 288.8/390.2 MB 32.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 290.0/390.2 MB 29.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 291.3/390.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 292.5/390.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 293.7/390.2 MB 29.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 294.9/390.2 MB 26.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 296.3/390.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 297.5/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 298.8/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 300.0/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 301.2/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 302.6/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 303.7/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 305.0/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 306.2/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 307.4/390.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 308.6/390.2 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 309.9/390.2 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 311.3/390.2 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 312.6/390.2 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 314.0/390.2 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 315.3/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 316.6/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 318.0/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 319.4/390.2 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 320.8/390.2 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 322.1/390.2 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 323.4/390.2 MB 28.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.8/390.2 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 326.0/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 327.5/390.2 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 328.8/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 330.1/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 331.3/390.2 MB 28.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 332.7/390.2 MB 28.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 334.2/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 335.4/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 336.8/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 338.1/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 339.4/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 340.9/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 342.1/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.5/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 344.9/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 346.2/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 347.6/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 348.7/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 350.1/390.2 MB 28.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 351.3/390.2 MB 27.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 352.5/390.2 MB 27.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.0/390.2 MB 28.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 355.4/390.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 356.8/390.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 358.3/390.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.7/390.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.7/390.2 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.4/390.2 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.9/390.2 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 364.0/390.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 365.6/390.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 367.0/390.2 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 368.8/390.2 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 370.4/390.2 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 371.9/390.2 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.5/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.9/390.2 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 376.2/390.2 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 377.7/390.2 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 379.3/390.2 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.1/390.2 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.8/390.2 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.3/390.2 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.1/390.2 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.7/390.2 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.0/390.2 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.2/390.2 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.4/4.4 MB 45.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.9/4.4 MB 36.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.4/4.4 MB 34.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 27.8 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.8/3.0 MB 38.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 31.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 27.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 38.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/26.4 MB 42.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 39.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.6/26.4 MB 36.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.1/26.4 MB 35.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.7/26.4 MB 35.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.5/26.4 MB 35.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.1/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.3/26.4 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.9/26.4 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.6/26.4 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.9/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.7/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.1/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.7/126.7 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 47.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 49.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 43.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 31.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.5/1.5 MB 47.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 31.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp311-cp311-win_amd64.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/283.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 283.7/283.7 kB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\EQUIPO\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\EQUIPO\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af006db0-c9b9-47ef-beda-58d12f125e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2d2992-63c4-4405-bab3-c23ae141ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  default student      balance        income\n",
      "0      No      No   729.526495  44361.625074\n",
      "1      No     Yes   817.180407  12106.134700\n",
      "2      No      No  1073.549164  31767.138947\n",
      "3      No      No   529.250605  35704.493935\n",
      "4      No      No   785.655883  38463.495879\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos Default\n",
    "ruta = \"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/default.csv\"\n",
    "# Verificamos los primeros datos\n",
    "print(data.head())\n",
    "\n",
    "# Separaramos las características (X) y el objetivo (y)\n",
    "X = data[['balance', 'income']]  # Ajustar según las columnas relevantes\n",
    "y = data['default'].apply(lambda x: 1 if x == 'Yes' else 0)  # Convertir a binario\n",
    "\n",
    "# Dividimos en conjuntos de entrenamiento y prueba (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizamos las características para la red neuronal\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e8da70-ade6-42bc-923d-74f5d697e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la regresión logística: 0.9695\n"
     ]
    }
   ],
   "source": [
    "#PASO2: ENTRENAMOS EL MODELO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definir y entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Precisión de la regresión logística: {accuracy_logistic:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84850882-c6d2-471b-9efa-beebbe691080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EQUIPO\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3694 - loss: 0.8913 - val_accuracy: 0.7594 - val_loss: 0.5673\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8583 - loss: 0.5198 - val_accuracy: 0.9638 - val_loss: 0.3557\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9587 - loss: 0.3560 - val_accuracy: 0.9638 - val_loss: 0.2223\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9675 - loss: 0.2564 - val_accuracy: 0.9638 - val_loss: 0.1613\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9688 - loss: 0.2047 - val_accuracy: 0.9638 - val_loss: 0.1305\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9656 - loss: 0.1864 - val_accuracy: 0.9638 - val_loss: 0.1133\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9652 - loss: 0.1560 - val_accuracy: 0.9638 - val_loss: 0.1023\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9641 - loss: 0.1511 - val_accuracy: 0.9638 - val_loss: 0.0952\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9653 - loss: 0.1364 - val_accuracy: 0.9638 - val_loss: 0.0906\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9690 - loss: 0.1268 - val_accuracy: 0.9638 - val_loss: 0.0874\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.9694 - loss: 0.1172 - val_accuracy: 0.9638 - val_loss: 0.0856\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9690 - loss: 0.1205 - val_accuracy: 0.9638 - val_loss: 0.0838\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9692 - loss: 0.1194 - val_accuracy: 0.9638 - val_loss: 0.0828\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9686 - loss: 0.1133 - val_accuracy: 0.9638 - val_loss: 0.0823\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9694 - loss: 0.1052 - val_accuracy: 0.9638 - val_loss: 0.0814\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9732 - loss: 0.0969 - val_accuracy: 0.9638 - val_loss: 0.0812\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.9683 - loss: 0.1042 - val_accuracy: 0.9638 - val_loss: 0.0809\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9631 - loss: 0.1113 - val_accuracy: 0.9638 - val_loss: 0.0811\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9668 - loss: 0.1018 - val_accuracy: 0.9638 - val_loss: 0.0807\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9705 - loss: 0.0982 - val_accuracy: 0.9638 - val_loss: 0.0808\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9705 - loss: 0.1053 - val_accuracy: 0.9638 - val_loss: 0.0810\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9625 - loss: 0.1128 - val_accuracy: 0.9638 - val_loss: 0.0810\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9694 - loss: 0.1006 - val_accuracy: 0.9638 - val_loss: 0.0810\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9678 - loss: 0.1084 - val_accuracy: 0.9638 - val_loss: 0.0804\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9704 - loss: 0.1035 - val_accuracy: 0.9638 - val_loss: 0.0815\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9703 - loss: 0.0974 - val_accuracy: 0.9638 - val_loss: 0.0810\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9649 - loss: 0.1179 - val_accuracy: 0.9638 - val_loss: 0.0812\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9714 - loss: 0.0967 - val_accuracy: 0.9638 - val_loss: 0.0804\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9698 - loss: 0.0880 - val_accuracy: 0.9638 - val_loss: 0.0794\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9672 - loss: 0.1052 - val_accuracy: 0.9638 - val_loss: 0.0797\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9694 - loss: 0.1005 - val_accuracy: 0.9644 - val_loss: 0.0792\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9701 - loss: 0.0926 - val_accuracy: 0.9644 - val_loss: 0.0791\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9700 - loss: 0.1015 - val_accuracy: 0.9644 - val_loss: 0.0795\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9742 - loss: 0.0893 - val_accuracy: 0.9644 - val_loss: 0.0791\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9703 - loss: 0.0933 - val_accuracy: 0.9644 - val_loss: 0.0786\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9695 - loss: 0.0970 - val_accuracy: 0.9650 - val_loss: 0.0783\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9739 - loss: 0.0868 - val_accuracy: 0.9644 - val_loss: 0.0791\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9723 - loss: 0.0853 - val_accuracy: 0.9644 - val_loss: 0.0796\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9652 - loss: 0.1105 - val_accuracy: 0.9644 - val_loss: 0.0796\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9727 - loss: 0.0832 - val_accuracy: 0.9650 - val_loss: 0.0787\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9687 - loss: 0.0986 - val_accuracy: 0.9650 - val_loss: 0.0785\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9698 - loss: 0.0976 - val_accuracy: 0.9650 - val_loss: 0.0790\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9679 - loss: 0.0982 - val_accuracy: 0.9650 - val_loss: 0.0793\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9684 - loss: 0.1018 - val_accuracy: 0.9650 - val_loss: 0.0793\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9715 - loss: 0.0840 - val_accuracy: 0.9650 - val_loss: 0.0792\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9701 - loss: 0.0897 - val_accuracy: 0.9650 - val_loss: 0.0792\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.9708 - loss: 0.0909 - val_accuracy: 0.9650 - val_loss: 0.0791\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9707 - loss: 0.0979 - val_accuracy: 0.9650 - val_loss: 0.0801\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9687 - loss: 0.0961 - val_accuracy: 0.9656 - val_loss: 0.0791\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9732 - loss: 0.0864 - val_accuracy: 0.9650 - val_loss: 0.0797\n"
     ]
    }
   ],
   "source": [
    "#Implementamos y entrenamos la red neuronal con keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Definir la red neuronal\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),  # Capa oculta con 10 unidades\n",
    "    Dropout(0.5),  # Dropout con una tasa del 50%\n",
    "    Dense(1, activation='sigmoid')  # Capa de salida para clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b8a6456-9311-499f-93c9-857b2502c9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n",
      "Precisión de la red neuronal: 0.9650\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el desempeño  de la red neuronal en el conjunto de prueba\n",
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Precisión de la red neuronal: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b523379-cb63-4c5f-bcb2-90b710b80b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación del desempeño de clasificación:\n",
      " - Precisión de la regresión logística: 0.9695\n",
      " - Precisión de la red neuronal: 0.9650\n"
     ]
    }
   ],
   "source": [
    "#Comparamos resultados\n",
    "print(\"Comparación del desempeño de clasificación:\")\n",
    "print(f\" - Precisión de la regresión logística: {accuracy_logistic:.4f}\")\n",
    "print(f\" - Precisión de la red neuronal: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68daab-14ba-4dbd-a007-635ccbe462d0",
   "metadata": {},
   "source": [
    "### **Pregunta 5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d75a3-8a05-43a9-8246-ee34881c4c40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Considere la implementación del modelo de **Redes Neuronales Convolucionales** $(CNN)$ utilizando la dataset **CIFAR 100** presentada en el notebook de clases. En esta implementación inicial, se alcanzó un **Accuracy** aproximado de **0.44**. Su tarea es desarrollar una nueva implementación que supere este valor de **Accuracy**. Para lograrlo, se le anima a experimentar con los siguientes aspectos del modelo:\n",
    "\n",
    "- **Arquitectura del Modelo:** Puede considerar la adición de más capas convolucionales y de pooling, incrementar el número de filtros por capa, o modificar el tamaño del kernel.\n",
    "\n",
    "- **Regularización:** Experimente con diferentes tasas de dropout para prevenir el sobreajuste.\n",
    "\n",
    "- **Entrenamiento:** Pruebe con distintos tamaños de batch que puedan influir en la convergencia del modelo durante el entrenamiento.\n",
    "\n",
    "- **Optimización:** Evalúe el uso de diferentes algoritmos de optimización para verificar si mejoran la precisión del modelo.\n",
    "\n",
    "#### La meta es ajustar estos parámetros para superar el **Accuracy** de **0.44** previamente alcanzado. Documente todas las modificaciones realizadas y los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ff7e8-20ba-4f63-900f-66fcb8a63bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
