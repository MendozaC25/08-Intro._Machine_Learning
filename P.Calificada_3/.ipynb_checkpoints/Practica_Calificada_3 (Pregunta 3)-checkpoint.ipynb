{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3bf0a9-39da-4699-8e6e-19e7f3c5bc65",
   "metadata": {},
   "source": [
    "# **Lista de ejercicios 3 (30 de octubre, 2024)**\n",
    "## Introducción a Machine Learning para CCSS\n",
    "\n",
    "### Integrantes: \n",
    "\n",
    "- Victoria Olivera García (20171137)\n",
    "- Víctor Manuel Raico Arce (F1092609)\n",
    "- Fernando Mendoza Canal (20105246)\n",
    "- Paolo Gutierrez Chochoca (F1120328)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e66059-a4f4-4cd6-94fc-2e750f63f51a",
   "metadata": {},
   "source": [
    "#### **Instrucciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52420ee-0378-401b-b65d-12d6e2a4f8b0",
   "metadata": {},
   "source": [
    "**1. Temas abordados:** Esta lista de ejercicios se enfoca en los temas: Tree Based Models &\n",
    "Neural Networks.\n",
    "\n",
    "**2. Formación de grupos:** Se permite la formación de grupos de hasta 5 integrantes.\n",
    "\n",
    "**3. Puntuación de ejercicios:** La lista contiene 5 ejercicios. Cada ejercicio vale 4 puntos.\n",
    "\n",
    "**4. Formato de entrega:** La resolución de los ejercicios debe presentarse en un archivo jupyter-notebook con todas las celdas ejecutadas.\n",
    "\n",
    "**5. Fecha límite de entrega:** La fecha límite para la entrega es el miércoles 06 de noviembre a las 11:59 pm. Un representante del equipo debe subir su solucionario a la actividad correspondiente en la plataforma Canvas. Los nombres y códigos de todos los participantes deben ser incluidos en el solucionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef7725-0af0-49c3-b9f4-735f5909b66d",
   "metadata": {},
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1d4e6ff1-7aa2-44a5-a541-f001e31ca96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad743272-670b-41cc-9f1d-cc0371f719c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a306369-573f-4d9f-b238-daa8667d5a8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7c05f-5961-428f-ac50-a811349d9952",
   "metadata": {},
   "source": [
    "#### Brinde una explicación detallada del algoritmo que se utiliza para implementar un **Árbol de Regresión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed2725-d8a3-4899-8882-acff9ceb1fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57e4762-bbab-4dff-8ee1-3fbce099a9cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0dbae-81c5-4412-a18d-cc012c8d3cd8",
   "metadata": {},
   "source": [
    "#### Considere la dataset Carseats para predecir Sales como variable cuantitativa (puede encontrar el conjunto de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/carseats.csv)). Para ello:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a42ae-328f-44cc-a961-81c6e4f17021",
   "metadata": {},
   "source": [
    "#### **a)** Divida los datos en conjuntos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e9a60-995c-4fcc-a2bd-ebf9ef279271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47693c6-69bf-493d-972c-fc9729b5386b",
   "metadata": {},
   "source": [
    "#### **b)** Ajuste un árbol de regresión al conjunto de entrenamiento. Interprete los resultados. <br>¿Qué valor de $MSE$ se obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3ba20-7a52-478a-a5d5-cf4e5efcf1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee2e33a2-aeea-404c-9266-5bd77db9aff0",
   "metadata": {},
   "source": [
    "#### **c)** Utilice el método **Bagging** para analizar estos datos. <br>¿Qué valor de $MSE$ obtiene para el conjunto de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861a6ae-82ea-4533-bb2b-b6a2baf48580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cde0c5cb-2979-4e08-b7fd-10ce15e25131",
   "metadata": {},
   "source": [
    "#### **d)** Utilice el método **Random Forest** para analizar los datos. Repita el procedimiento descrito en el punto 3. <br>Describa el efecto de $m$, el número de variables consideradas en cada división, sobre la tasa de error obtenida. <br>Utilice la función $features\\_importance()$ para determinar qué variables son las más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ff48d-fdbf-4448-b31d-341ac933e4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139d4d4a-34dd-4595-9315-ae3a81bcfd77",
   "metadata": {},
   "source": [
    "#### **e)** Utilice el método **Gradient Boosting**. Repita el procedimiento descrito en el punto 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459fe9d-d772-4ea8-a545-090c0c22d465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e41005-f56b-455f-9913-a2d0bfdc9be9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 3**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4397-5569-48be-9b76-f978e69d7463",
   "metadata": {},
   "source": [
    "#### Aplique los métodos **Boosting, Bagging y Random Forest** a una dataset de su elección. Asegúrese de dividir los datos en los conjuntos de entrenamiento y de prueba, ajustar los modelos sobre el conjunto de entrenamiento y evaluar su desempeño sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usará el dataset College\n",
    "ruta = \"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/college.csv\"\n",
    "data = pd.read_csv(ruta)\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Codificando a valores binarios la variable 'Private'\n",
    "mapa = {\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "}\n",
    "\n",
    "data['Private'] = data['Private'].map(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58439e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo variables explicativas y variable explicada\n",
    "X = data.drop(columns='Apps')\n",
    "y = data['Apps']\n",
    "\n",
    "# Dividiendo los datos entre train y test (30% para el data test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20241104)\n",
    "\n",
    "# Escalando los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81df7b7",
   "metadata": {},
   "source": [
    "#### ¿Cuán precisos son los resultados si los compara con métodos regresión lineal/logística y/o métodos de **Regularización**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47528a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos Lasso y Ridge se ajusta primero los alpha óptimos:\n",
    "# Definir el rango de alphas para Lasso y Ridge\n",
    "alpha_values = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Modelo Lasso con GridSearchCV\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid=alpha_values, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "best_lasso = lasso_cv.best_estimator_\n",
    "\n",
    "# Modelo Ridge con GridSearchCV\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid=alpha_values, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "best_ridge = ridge_cv.best_estimator_\n",
    "\n",
    "# Modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': best_lasso,\n",
    "    'Ridge': best_ridge,\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Bagging': BaggingRegressor(n_estimators=100, random_state=20241104),\n",
    "    'Boosting': GradientBoostingRegressor(n_estimators=100, random_state=20241104)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fa45a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.479619e+06</td>\n",
       "      <td>1216.395955</td>\n",
       "      <td>0.863759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.415299e+06</td>\n",
       "      <td>1189.663551</td>\n",
       "      <td>0.869682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.477369e+06</td>\n",
       "      <td>1215.470580</td>\n",
       "      <td>0.863966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>8.833714e+05</td>\n",
       "      <td>939.878407</td>\n",
       "      <td>0.918661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>8.615275e+05</td>\n",
       "      <td>928.185066</td>\n",
       "      <td>0.920672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosting</th>\n",
       "      <td>8.827712e+05</td>\n",
       "      <td>939.559055</td>\n",
       "      <td>0.918716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE         RMSE        R2\n",
       "Linear Regression  1.479619e+06  1216.395955  0.863759\n",
       "Lasso              1.415299e+06  1189.663551  0.869682\n",
       "Ridge              1.477369e+06  1215.470580  0.863966\n",
       "Random Forest      8.833714e+05   939.878407  0.918661\n",
       "Bagging            8.615275e+05   928.185066  0.920672\n",
       "Boosting           8.827712e+05   939.559055  0.918716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511423ab",
   "metadata": {},
   "source": [
    "#### ¿Cuál de todos los modelos implementados muestra un mejor desempeño?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940774da",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "\n",
    "Según lo observado en el cuadro anterior, se tiene los siguientes resultados:\n",
    "- El modelo *Bagging* muestra el menor RMSE (928.19), junto con el mayor $R^2$, lo que sugiere que es el modelo con mejor desempeño en esta comparación de modelos.\n",
    "- Los modelos de *Random Forest* y *Boosting* están cerca del modelo *Bagging*.\n",
    "- Los modelos de *regresión lineal* y de regularización (*Ridge* y *Lasso*) tienen un peor rendimiento en el RMSE y $R^2$.\n",
    "- En conclusión, el modelo *Bagging* muestra el mejor desempeño dado que tiene el menor RMSE y mayor $R^2$ en comparación con los resultados de los otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e6e9e-ce7d-46ef-bee2-94222d03496a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e57994-d1e3-4b83-80b4-4b717b927336",
   "metadata": {},
   "source": [
    "#### Implemente una red neuronal con la database **Default** (puede encontrar el set de datos [aquí](https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/default.csv)). Use una capa oculta con 10 unidades y regularización por droput. Compare el desempeño de clasificación con respecto al de la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d2992-63c4-4405-bab3-c23ae141ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b68daab-14ba-4dbd-a007-635ccbe462d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Pregunta 5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d75a3-8a05-43a9-8246-ee34881c4c40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Considere la implementación del modelo de **Redes Neuronales Convolucionales** $(CNN)$ utilizando la dataset **CIFAR 100** presentada en el notebook de clases. En esta implementación inicial, se alcanzó un **Accuracy** aproximado de **0.44**. Su tarea es desarrollar una nueva implementación que supere este valor de **Accuracy**. Para lograrlo, se le anima a experimentar con los siguientes aspectos del modelo:\n",
    "\n",
    "- **Arquitectura del Modelo:** Puede considerar la adición de más capas convolucionales y de pooling, incrementar el número de filtros por capa, o modificar el tamaño del kernel.\n",
    "\n",
    "- **Regularización:** Experimente con diferentes tasas de dropout para prevenir el sobreajuste.\n",
    "\n",
    "- **Entrenamiento:** Pruebe con distintos tamaños de batch que puedan influir en la convergencia del modelo durante el entrenamiento.\n",
    "\n",
    "- **Optimización:** Evalúe el uso de diferentes algoritmos de optimización para verificar si mejoran la precisión del modelo.\n",
    "\n",
    "#### La meta es ajustar estos parámetros para superar el **Accuracy** de **0.44** previamente alcanzado. Documente todas las modificaciones realizadas y los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ff7e8-20ba-4f63-900f-66fcb8a63bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
